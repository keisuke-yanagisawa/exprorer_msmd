#!/usr/bin/env python

from script.utilities.logger import logger
import argparse
import tempfile
import os
import pathlib

from joblib import Parallel, delayed

from script.utilities import util
from script.utilities.GPUtil import get_gpuids
from script.genpmap import gen_pmap
from script.utilities.pmd import convert as pmd_convert
from script.generate_msmd_system import generate_msmd_system
from script.addvirtatom2top import addvirtatom2top
from script.addvirtatom2gro import addvirtatom2gro
from script.add_posredefine2top import add_posredefine2top
from script.mdrun import prepare_sequence, prepare_md_files

VERSION = "0.2.0"


def preprocess(index, setting, debug=False):
    prepdirpath = f'{setting["general"]["workdir"]}/system{index}/prep'
    pathlib.Path(prepdirpath).mkdir(parents=True, exist_ok=True)

    PROBE_ID = setting["input"]["probe"]["cid"]
    JOB_NAME = setting["general"]["name"]
    top = f"{prepdirpath}/{JOB_NAME}.top"
    gro = f"{prepdirpath}/{JOB_NAME}.gro"
    pdb = f"{prepdirpath}/{JOB_NAME}.pdb"

    if os.path.exists(top) \
       and os.path.exists(gro) \
       and os.path.exists(pdb):
        return top, gro, pdb

    exe_gromacs = setting["general"]["executables"]["gromacs"]

    # create a protein-water-probe system
    _, tmptop = tempfile.mkstemp(suffix=".top")
    _, tmpgro = tempfile.mkstemp(suffix=".gro")
    parm7, rst7 = generate_msmd_system(setting, debug=debug, seed=index)
    pmd_convert(parm7, tmptop, inxyz=rst7, outxyz=tmpgro)

    # add virtual atoms for pseudo repulsion between probes
    top_string = open(tmptop).read()
    top_string = addvirtatom2top(top_string, PROBE_ID)
    gro_string = open(tmpgro).read()
    gro_string = addvirtatom2gro(gro_string, PROBE_ID)

    # define position restraints of heavy atoms
    top_string = add_posredefine2top(
        top_string,
        gro_string,
        PROBE_ID
    )

    open(top, "w").write(top_string)
    open(gro, "w").write(gro_string)

    # create a pdb file with virtual atoms
    os.system(f"""
    {exe_gromacs} trjconv -s {gro} \
    -f {gro} \
    -o {pdb} <<EOF
    0
    EOF
    """)

    return top, gro, pdb


def execute_single_simulation(index, setting, gpuid, ncpus, top, gro, pdb, debug=False):
    """
    Execute a single MSMD simulation with preprocessing and postprocessing.
    """

    simdirpath = f'{setting["general"]["workdir"]}/system{index}/simulation'
    pathlib.Path(simdirpath).mkdir(parents=True, exist_ok=True)

    JOB_NAME = setting["general"]["name"]

    exe_gromacs = setting["general"]["executables"]["gromacs"]

    os.system(f"cp {top} {simdirpath}/input.top")
    os.system(f"cp {gro} {simdirpath}/input.gro")
    os.system(f"cp {pdb} {simdirpath}/input.pdb")  # is it needed?
    top = f"{simdirpath}/input.top"
    gro = f"{simdirpath}/input.gro"
    pdb = f"{simdirpath}/input.pdb"

    # generate a gromacs index file
    os.system(f"""
    cd {simdirpath} &&
    {exe_gromacs} make_ndx -f {gro} << EOF
    q
    EOF
    """)

    setting["exprorer_msmd"]["sequence"] = prepare_sequence(
        setting["exprorer_msmd"]["sequence"],
        setting["exprorer_msmd"]["general"]
    )

    # generate mdp files and a shell script to run each simulation sequentially
    prepare_md_files(
        setting["exprorer_msmd"]["sequence"],
        simdirpath,
        JOB_NAME,
        top=top,
        gro=gro,
        out_traj=f"{simdirpath}/{JOB_NAME}.xtc"
    )

    # execute simulation
    os.system(f"""
    unset OMP_NUM_THREADS ; \
    export CUDA_VISIBLE_DEVICES="{gpuid}" ; \
    cd {simdirpath} && \
    GMX={exe_gromacs} bash mdrun.sh {ncpus}
    """)

    return f"{simdirpath}/{JOB_NAME}.xtc"


def postprocess(index, setting, top, traj, debug=False):
    sysdirpath = f'{setting["general"]["workdir"]}/system{index}'

    # generate pmap files
    gen_pmap(sysdirpath,
             setting["general"],
             setting["input"],
             setting["map"],
             traj=traj,
             top=top,
             debug=debug)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Run MSMD simulation")
    parser.add_argument("setting_yaml")
    parser.add_argument("-v,--verbose", dest="verbose", action="store_true")
    parser.add_argument("--debug", action="store_true")
    parser.add_argument("--skip-preprocess", action="store_true")
    parser.add_argument("--skip-simulation", action="store_true")
    parser.add_argument("--skip-postprocess", action="store_true")
    parser.add_argument("--version", action="version", version=VERSION)
    parser.add_argument("--iter-index", help=argparse.SUPPRESS)  # overwrite iter_index of config yaml
    args = parser.parse_args()

    # initial logger level is "warn"
    if args.debug:
        logger.setLevel("debug")
    elif args.verbose:
        logger.setLevel("info")

    logger.info(f"read yaml: {args.setting_yaml}")
    setting = util.parse_yaml(args.setting_yaml)
    if args.iter_index is not None:
        setting["general"]["iter_index"] = args.iter_index
    indices = set(util.expand_index(setting["general"]["iter_index"]))

    jobname = setting["general"]["name"]
    workdir = setting["general"]["workdir"]
    logger.info(f"job name: {jobname}")
    logger.info(f"workdir: {workdir}")

    # Count num. of GPUs and allocate CPU cores to each GPU
    # Raise EnvironmentError if GPU is not available
    gpuids = get_gpuids()
    ngpus = len(gpuids)
    if not setting["general"]["multiprocessing"]:
        ngpus = 1
    ncpus = os.cpu_count()
    ncpus = 1 if ncpus is None else ncpus
    ncpus_per_gpu = ncpus // len(get_gpuids(ignore_cuda_visible_devices=True))
    if ncpus_per_gpu == 0:
        raise EnvironmentError("The number of CPU threads must be "
                               "equal to or greater than the number of available GPUs")

    logger.info(f"{ncpus} threads are detected")
    logger.info(f"{ngpus} parallel execution with {ncpus_per_gpu} CPU threads per process")

    # prepare systems
    # n_jobs = num of CPU cores, not num of GPUs
    if not args.skip_preprocess:
        files = Parallel(n_jobs=ncpus, backend='threading')(
            delayed(preprocess)(idx, setting, debug=args.debug)
            for idx in indices
        )
        tops = [elem[0] for elem in files]
        gros = [elem[1] for elem in files]
        pdbs = [elem[2] for elem in files]
    else:
        prepdirpath = '{workdir}/system{index}/prep'
        tops = [prepdirpath.format(workdir=workdir, index=idx) + f"/{jobname}.top" for idx in indices]
        gros = [prepdirpath.format(workdir=workdir, index=idx) + f"/{jobname}.gro" for idx in indices]
        pdbs = [prepdirpath.format(workdir=workdir, index=idx) + f"/{jobname}.pdb" for idx in indices]

    # execute MSMD simulations parallelly
    if not args.skip_simulation:
        gpuids = (gpuids * len(indices))[:len(indices)]
        trajectories = Parallel(n_jobs=ngpus, backend='threading')(
            delayed(execute_single_simulation)(idx, setting, gpuid, ncpus_per_gpu, top=top, gro=gro, pdb=pdb, debug=args.debug)
            for idx, gpuid, top, gro, pdb in zip(indices, gpuids, tops, gros, pdbs)
        )
    else:
        simdirpath = '{workdir}/system{index}/simulation'
        trajectories = [simdirpath.format(workdir=workdir, index=idx) + f"/{jobname}.xtc" for idx in indices]

    # postprocess (generate PMAPs)
    # n_jobs = num of CPU cores, not num of GPUs
    if not args.skip_postprocess:
        Parallel(n_jobs=ncpus, backend='threading')(
            delayed(postprocess)(idx, setting, top=top, traj=traj, debug=args.debug)
            for idx, top, traj in zip(indices, tops, trajectories)
        )
    else:
        pass  # there is no output by Parallel - postprocess
