#!/usr/bin/env python

import argparse
import os
import shutil
import tempfile
from pathlib import Path

import numpy as np
import parmed as pmd
from joblib import Parallel, delayed

from script.add_posredefine2top import embed_posre
from script.addvirtatom2gro import addvirtatom2gro
from script.addvirtatom2top import addvirtatom2top
from script.generate_msmd_system import generate_msmd_system
from script.genpmap import gen_pmap
from script.mdrun import prepare_md_files, prepare_sequence, run_md_sequence
from script.setting import parse_yaml
from script.utilities import util
from script.utilities.const import IONS
from script.utilities.GPUtil import get_gpuids, is_mps_control_running
from script.utilities.logger import logger
from script.utilities.pmd import convert as pmd_convert

VERSION = "0.2.0"


def preprocess(index: int, setting: dict, debug=False) -> tuple[Path, Path, Path]:
    prepdirpath: Path = Path(f'{setting["general"]["workdir"]}/system{index}/prep')
    prepdirpath.mkdir(parents=True, exist_ok=True)

    PROBE_ID = setting["input"]["probe"]["cid"]
    JOB_NAME = setting["general"]["name"]
    top: Path = prepdirpath / f"{JOB_NAME}.top"
    gro: Path = prepdirpath / f"{JOB_NAME}.gro"
    pdb: Path = prepdirpath / f"{JOB_NAME}.pdb"

    if top.exists() and gro.exists() and pdb.exists():
        return top, gro, pdb

    exe_gromacs: Path = Path(setting["general"]["executables"]["gromacs"])

    # create a protein-water-probe system
    tmptop: Path = Path(tempfile.mkstemp(suffix=".top")[1])
    tmpgro: Path = Path(tempfile.mkstemp(suffix=".gro")[1])
    parm7, rst7 = generate_msmd_system(setting, debug=debug, seed=index)
    system_obj = pmd.load_file(str(parm7), str(rst7))
    atom_ids_protein_nonH = (
        np.where(system_obj._get_selection_array(f"!@H* & !:WAT,{PROBE_ID},{','.join(IONS)}"))[0] + 1
    )

    # add virtual atoms for pseudo repulsion between probes
    pmd_convert(parm7, tmptop, inxyz=rst7, outxyz=tmpgro)
    top_string: str = tmptop.open().read()
    top_string: str = addvirtatom2top(top_string, PROBE_ID)
    gro_string: str = tmpgro.open().read()
    gro_string: str = addvirtatom2gro(gro_string, PROBE_ID)

    # define position restraints of heavy atoms
    top_string = embed_posre(
        top_string, atom_ids_protein_nonH, prefix="POSRES", strength=[1000, 500, 200, 100, 50, 20, 10, 0]
    )

    top.write_text(top_string)
    gro.write_text(gro_string)

    # create a pdb file with virtual atoms
    os.system(
        f"""
    {exe_gromacs} trjconv -s {gro} \
    -f {gro} \
    -o {pdb} <<EOF
    0
    EOF
    """
    )

    return top, gro, pdb


def execute_single_simulation(
    index: int, setting: dict, gpuid: int, ncpus: int, top: Path, gro: Path, pdb: Path, debug=False
) -> Path:
    """
    Execute a single MSMD simulation with preprocessing and postprocessing.
    """

    simdirpath = Path(f'{setting["general"]["workdir"]}/system{index}/simulation')
    simdirpath.mkdir(parents=True, exist_ok=True)

    JOB_NAME: str = setting["general"]["name"]

    exe_gromacs: Path = Path(setting["general"]["executables"]["gromacs"])

    new_top = simdirpath / "input.top"
    new_gro = simdirpath / "input.gro"
    new_pdb = simdirpath / "input.pdb"
    shutil.copy(top, new_top)
    shutil.copy(gro, new_gro)
    shutil.copy(pdb, new_pdb)
    top = new_top
    gro = new_gro
    pdb = new_pdb

    # generate a gromacs index file
    os.system(
        f"""
    cd {simdirpath} &&
    {exe_gromacs} make_ndx -f {gro} << EOF
    q
    EOF
    """
    )

    setting["exprorer_msmd"]["sequence"] = prepare_sequence(
        setting["exprorer_msmd"]["sequence"], setting["exprorer_msmd"]["general"]
    )

    # generate mdp files and a shell script to run each simulation sequentially
    prepare_md_files(
        index,
        setting["exprorer_msmd"]["sequence"],
        simdirpath,
        JOB_NAME,
        top=top,
        gro=gro,
        out_traj=simdirpath / f"{JOB_NAME}.xtc",
    )

    return run_md_sequence(gpuid, simdirpath, exe_gromacs, ncpus, JOB_NAME)




def postprocess(index: int, setting, top: Path, traj: Path, debug: bool = False):
    workdir = Path(setting["general"]["workdir"])
    sysdirpath = workdir / f"system{index}"

    # generate pmap files
    gen_pmap(sysdirpath, setting["general"], setting["input"], setting["map"], traj=traj, top=top, debug=debug)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Run MSMD simulation")
    parser.add_argument("setting_yaml")
    parser.add_argument("-v,--verbose", dest="verbose", action="store_true")
    parser.add_argument("--debug", action="store_true")
    parser.add_argument("--skip-preprocess", action="store_true")
    parser.add_argument("--skip-simulation", action="store_true")
    parser.add_argument("--skip-postprocess", action="store_true")
    parser.add_argument("--version", action="version", version=VERSION)
    parser.add_argument("--iter-index", help=argparse.SUPPRESS)  # overwrite iter_index of config yaml
    args = parser.parse_args()

    # initial logger level is "warn"
    if args.debug:
        logger.setLevel("debug")
    elif args.verbose:
        logger.setLevel("info")

    logger.info(f"read yaml: {args.setting_yaml}")
    setting = parse_yaml(Path(args.setting_yaml))
    if args.iter_index is not None:
        setting["general"]["iter_index"] = args.iter_index
    indices = set(util.expand_index(setting["general"]["iter_index"]))

    jobname = setting["general"]["name"]
    workdir = Path(setting["general"]["workdir"])
    logger.info(f"job name: {jobname}")
    logger.info(f"workdir: {workdir}")

    # Count num. of GPUs and allocate CPU cores to each GPU
    # Raise EnvironmentError if GPU is not available

    num_process_per_gpu = setting["general"]["num_process_per_gpu"]
    gpuids = get_gpuids() * num_process_per_gpu
    print(gpuids)
    if num_process_per_gpu > 1:
        if not is_mps_control_running():
            raise RuntimeError("nvidia-cuda-mps-server is not running. Please start it before using MPS.")
        else:
            logger.info("nvidia-cuda-mps-server is running.")

    ngpus = len(gpuids)
    if not setting["general"]["multiprocessing"]:
        ngpus = 1
    ncpus = len(os.sched_getaffinity(0))
    ncpus = 1 if ncpus is None else ncpus

    ratio_available_gpus = len(get_gpuids(ignore_cuda_visible_devices=False)) / len(
        get_gpuids(ignore_cuda_visible_devices=True)
    )
    ncpus_per_run = int(ncpus * ratio_available_gpus / len(gpuids))
    if ncpus_per_run == 0:
        raise EnvironmentError(
            "The number of CPU threads must be equal to " "or greater than the number of runs executed simultaneously"
        )

    logger.info(f"{ncpus} threads are detected")
    logger.info(f"{ngpus} parallel execution with {ncpus_per_run} CPU threads per process")

    # prepare systems
    # n_jobs = num of CPU cores, not num of GPUs
    if not args.skip_preprocess:
        files: list[tuple[Path, Path, Path]] = Parallel(n_jobs=ncpus, backend="threading")(
            delayed(preprocess)(idx, setting, debug=args.debug) for idx in indices
        )  # type: ignore
        tops = [elem[0] for elem in files]
        gros = [elem[1] for elem in files]
        pdbs = [elem[2] for elem in files]
    else:
        tops = [workdir / f"system{index}" / "prep" / f"{jobname}.top" for index in indices]
        gros = [workdir / f"system{index}" / "prep" / f"{jobname}.gro" for index in indices]
        pdbs = [workdir / f"system{index}" / "prep" / f"{jobname}.pdb" for index in indices]

    # execute MSMD simulations parallelly
    if not args.skip_simulation:
        gpuids = (gpuids * len(indices))[: len(indices)]
        trajectories: list[Path] = Parallel(n_jobs=ngpus, backend="threading")(
            delayed(execute_single_simulation)(
                idx, setting, gpuid, ncpus_per_run, top=top, gro=gro, pdb=pdb, debug=args.debug
            )
            for idx, gpuid, top, gro, pdb in zip(indices, gpuids, tops, gros, pdbs)
        )  # type: ignore
    else:
        trajectories = [workdir / f"system{idx}" / "simulation" / f"{jobname}.xtc" for idx in indices]

    # postprocess (generate PMAPs)
    # n_jobs = num of CPU cores, not num of GPUs
    if not args.skip_postprocess:
        Parallel(n_jobs=ncpus, backend="threading")(
            delayed(postprocess)(idx, setting, top=top, traj=traj, debug=args.debug)
            for idx, top, traj in zip(indices, tops, trajectories)
        )
    else:
        pass  # there is no output by Parallel - postprocess
